#' @title FaaS - updating models in forecast pack generated by scale modeling
#'
#' @description Model update is a module that allows the user to update the models (in the \code{forecast_pack}) obtained using FaaS scale modeling, but using a \code{new_data}.
#' This means that the same specifications used initially will remain the same in the new updated \code{forecast_pack}. \cr
#' You can update one or more \code{forecast_pack}'s at a time, and you should also input a \code{new_data} for each forecast_pack.
#' The \code{new_data} should have all variables used in the original models, with the exact same names.
#'
#' @param pack_list list with information about all packs to be updated. For each pack a list with a \code{forecast_pack} and a \code{new_data} should be provided. See examples below.
#' @param ... advanced parameters.
#' @param date_variable name of variable with date information in all \code{new_data} in \code{pack_list}.
#' @param date_format format of \code{date_variable} in all \code{new_data} in \code{pack_list}.
#' @param project_name project name. A string with character and/or numeric inputs that should be at most 50 characters long. Special characters will be removed.
#' @param cv_update TRUE or FALSE, indicating whether cross validation should be ran again. Default: FALSE.
#' @param model_spec list containing: \code{fill_forecast}, \code{n_steps}, \code{n_windows} and \code{cv_summary}, see details for its description. All arguments are optional, however \code{n_steps}, \code{n_windows} and \code{cv_summary} should only be used when \code{cv_update = TRUE}. Default: list().
#' @param base_dates TRUE or FALSE, indicating whether initial date in modeling should be kept for update, if possible. Default: TRUE.
#' @param outlier_update TRUE or FALSE, indicating whether a new search for outliers should be conducted. Search for outliers will be done only when \code{cv_update} = TRUE. Default is TRUE when \code{cv_update} is TRUE, and FALSE otherwise.
#' @param breakdown TRUE, FALSE or vector with 'row_id' of models to run breakdown (max of 3 models). If \code{breakdown} is TRUE, model breakdown will be calculated for the first 3 arima models. If \code{breakdown} is FALSE, model breakdown from previous modeling will be removed from \code{forecast_pack}. Default is TRUE when \code{cv_update} is TRUE, and FALSE otherwise.
#' @param save_local [DEV ONLY] directory to save base64 with body that would be sent to the API. With this parameter the function will not send your modeling request to the API. Default: NULL.
#' @return Success or error message of API request.
#'
#' @details \itemize{
#' \item All models inside the provided \code{forecast_pack} will be updated, and their original order is maintained. However, if any model no longer converges, it will be removed from the outputted \code{forecast_pack}.
#' \item Model combinations will be updated only when all models used to compose the combination can be properly updated.
#' \item Some initial checks are performed in the files sent via \code{run_update} before the request is sent. If there is any inconsistency you will be informed in your R console.
#' \item All arguments in \code{model_spec} are optional. If left undefined, original specifications are retained from \code{forecast_pack}.
#' \item When \code{cv_update = FALSE}, the only argument passed in \code{model_spec} is \code{fill_forecast}. When \code{cv_update = TRUE} the other arguments are also allowed.
#' \item \code{model_spec}'s description:
#' \itemize{
#'   \item \code{fill_forecast}: if TRUE, it enables forecasting explanatory variables in order to avoid NAs in future values. Can be set to TRUE or FALSE.
#'   \item \code{n_steps}: forecast horizon that will be used in the cross-validation (if 3, 3 months ahead; if 12, 12 months ahead, etc.). \code{n_steps} should be an integer greater than or equal to 1. It is recommended that \code{n_steps}+\code{n_windows}-1 does not exceed 30\% of the length of your data.
#'   \item \code{n_windows}: how many windows the size of ‘Forecast Horizon’ will be evaluated during cross-validation (CV). \code{n_windows} should be an integer greater than or equal to 1. It is recommended that \code{n_steps}+\code{n_windows}-1 does not exceed 30\% of the length of your data.
#'   \item \code{cv_summary}:determines whether mean or median will be used to calculate the summary statistic of the accuracy measure over the CV windows. Can be set to 'mean' or 'median'.
#' }
#' }
#'
#' @examples
#' \dontrun{
#'  ## In order to run these examples, you will need to load your own forecast_pack's, which are
#'  ## the results of modeling run_models.
#'
#'  ## EXAMPLE 1 - Updating one forecast_pack with cv_update = FALSE
#'
#'  # Load dataset and forecast_pack
#'  # Load a data frame with our data
#'  dataset_1 <- readxl::read_excel("your_path/inputs/dataset_1.xlsx")
#'
#'  # Load forecast_pack with models
#'  forecast_pack_1 <- readRDS("your_path/forecast_1_fs_pim.rds")
#'
#'  # Put it inside a list and name the list with the elements' name
#'  pack1 <- list(forecast_pack = forecast_pack_1,
#'                new_data = dataset_1)
#'
#'  # Put the list inside the pack_list
#'  pack_list_ex1 <-  list(pack1)
#'
#'  # Also, specify the date variable and its format
#'  date_variable <- "DATE_VARIABLE"
#'  date_format <- '%Y-%m-%d' # or'%m/%d/%Y'
#'
#'  # Set Project Name
#'  project_name <- "example_project"
#'
#'  # Send request
#'  faas4i::run_update(pack_list = pack_list_ex1, date_variable = date_variable,
#'                     date_format = date_format, project_name = project_name,
#'                     cv_update = FALSE)
#'
#'  ## EXAMPLE 2 - Using the same setup as example 1, but updating three forecast_packs at once
#'
#'  # Load datasets and forecast_packs
#'  # Load data frames with our data
#'  dataset_1 <- readxl::read_excel("your_path/dataset_1.xlsx")
#'  dataset_2 <- readxl::read_excel("your_path/dataset_2.xlsx")
#'  dataset_3 <- readxl::read_excel("your_path/dataset_3.xlsx")
#'
#'  # Load forecast_pack with models
#'  forecast_pack_1 <- readRDS("your_path/forecast_1_fs_pim.rds")
#'  forecast_pack_2 <- readRDS("your_path/forecast_2_fs_pmc.rds")
#'  forecast_pack_3 <- readRDS("your_path/forecast_3_fs_pib.rds")
#'
#'  # Put each forecast pack and new dataset inside a list and name the
#'  # list with the elements' name
#'  pack1 <- list(forecast_pack = forecast_pack_1,
#'                new_data = dataset_1)
#'  pack2 <- list(forecast_pack = forecast_pack_2,
#'                new_data = dataset_2)
#'  pack3 <- list(forecast_pack = forecast_pack_3,
#'                new_data = dataset_3)
#'
#'  # Put the list inside the pack_list
#'  pack_list_ex2 <-  list(pack1,
#'                         pack2,
#'                         pack3)
#'
#'  # Also, specify the date variable and its format (must have the same name in all datasets)
#'  date_variable <- "DATE_VARIABLE"
#'  date_format <- '%Y-%m-%d'
#'
#'  # Send request
#'  faas4i::run_update(pack_list = pack_list_ex2, date_variable = date_variable,
#'                     date_format = date_format, project_name = project_name,
#'                     cv_update = FALSE)
#'
#'  ## EXAMPLE 3 - Using the same setup as example 2, but allowing the accuracy measures
#'  ## to be updated by setting cv_update = TRUE, and also setting the full model_spec.
#'  ## Remember that all arguments in model_spec are optional.
#'
#'  # Modeling settings
#'  model_spec <- list(fill_forecast = TRUE,
#'                     n_steps = 12,
#'                     n_windows = 12,
#'                     cv_summary = 'median')
#'
#'  # Send request
#'  faas4i::run_update(pack_list = pack_list_ex2, date_variable = date_variable,
#'                     date_format = date_format, project_name = project_name,
#'                     cv_update = TRUE,
#'                     model_spec = model_spec)
#' }
#' @seealso
#'  \code{\link[httr]{POST}}
#' @rdname run_update
#' @export
#' @importFrom httr insensitive POST add_headers use_proxy content status_code
#' @importFrom utils str
run_update <- function(pack_list, date_variable, date_format, project_name,
                       cv_update = FALSE, model_spec = list(),
                       outlier_update = NULL, breakdown = NULL,
                       base_dates = TRUE, save_local = NULL, ...) {

  extra_arguments <- list(...)

  if (any(! names(extra_arguments) %in% c("version_check","force_request", "proxy_url", "proxy_port"))){
    invalid_args <- names(extra_arguments)[! names(extra_arguments) %in% c("version_check","force_request", "proxy_url", "proxy_port")]
    stop(paste0("Unexpected extra argument(s): ", paste0(invalid_args, collapse = ", "),"."))
  }

  if (is.null(extra_arguments$version_check)) extra_arguments$version_check <- TRUE

  if(extra_arguments$version_check){
    update_package <- package_version_check(proxy_url = extra_arguments$proxy_url,
                                            proxy_port = extra_arguments$proxy_port)
    if(update_package) return(invisible())
  }

  # Gera o token de autenticação no auth0 auth0
  access_token <- get_access_token()

  # Setting dummy user_email
  user_email <- 'user@legitmail.com'
  ## If force_request was not defined, we set it to FALSE
  if (is.null(extra_arguments$force_request)) extra_arguments$force_request <- FALSE

  ## If outlier_update was not defined, we set it to TRUE if cv_update is TRUE
  if (is.null(outlier_update) && cv_update == TRUE) outlier_update <- TRUE
  ## If outlier_update was not defined, we set it to FALSE if cv_update is FALSE
  if (is.null(outlier_update) && cv_update == FALSE) outlier_update <- FALSE

  ## If breakdown was not defined, we set it to TRUE if cv_update is TRUE
  if (is.null(breakdown) && cv_update == TRUE) breakdown <- TRUE
  ## If breakdown was not defined, we set it to FALSE if cv_update is FALSE
  if (is.null(breakdown) && cv_update == FALSE) breakdown <- FALSE

  ## Making sure arguments of list are not named
  names(pack_list) <- NULL

  validate_user_input_update(pack_list, date_variable, date_format, project_name, user_email,
                             cv_update, model_spec, base_dates = base_dates,
                             force_request = extra_arguments$force_request,
                             outlier_update = outlier_update,
                             breakdown = breakdown)

  ## Filtering the first 25 models in forecast_pack and variables in new_data that are only numeric
  for (i in 1:length(pack_list)){
    if ( nrow(pack_list[[i]]$forecast_pack) > 25){
      message("Reducing number of models in forecast_pack ", i, " to maximum supported in this version, 25.")
      pack_list[[i]]$forecast_pack <- pack_list[[i]]$forecast_pack[1:25,]
    }

    numeric_check <- which(sapply(pack_list[[i]]$new_data, is.numeric) == TRUE)
    names_keep <- c(date_variable, names(numeric_check))
    names_drop <- setdiff(names(pack_list[[i]]$new_data), names_keep)

    if(length(names_drop) > 0){
      message("Removing nonnumeric variables from new_data ", i, ".")
      pack_list[[i]]$new_data <- pack_list[[i]]$new_data[,names_keep, drop = FALSE]
    }
    rm(numeric_check, names_keep,names_drop)
  }

  ## If cv_update is FALSE, 'outlier_update' should be set to FALSE, and 'n_steps', 'n_windows' and
  ## 'cv_summary' in 'model_spec' should be NULL
  if ( cv_update == FALSE ){
    outlier_update <- FALSE
    model_spec[["n_steps"]] <- NULL
    model_spec[["n_windows"]] <- NULL
    model_spec[["cv_summary"]] <- NULL
  }

  body <- prepare_body_update(pack_list, date_variable, date_format, project_name, user_email,
                              cv_update, model_spec, base_dates = base_dates,
                              force_request = extra_arguments$force_request,
                              outlier_update = outlier_update,
                              breakdown = breakdown)

  ## If the argument 'save_local' was passed, we save 'body' in path provided
  if(!is.null(save_local)){
    if( dir.exists(save_local) == FALSE){
      stop(paste0(save_local, " does not exist."))
    } else{
      ## Getting time stamp to save file and creating name of file
      time_stamp <- gsub("\\.", "", as.numeric(Sys.time()))
      file_name <- paste0(save_local,"/b64ru_", project_name,"_", time_stamp)
      ## Saving body to file location defined
      write(body$body, file = file_name)
      warning("This project was only saved locally, it was not sent to the modeling API.")
      return(message(paste0("Body saved as ", file_name)))
    }
  }

  # Define a chave de acesso para poder fazer requisições via API ============
  headers <- c("authorization"= paste0("Bearer ", access_token))
  headers <- httr::insensitive(headers)

  ### Envia requisição POST ==================================================
  body_size <- object.size(body)/1000000 # body size in megabits
  base_url <- get_url("update", body_size = body_size)

  # posted <- 0
  # print(length(body))
  # for (i in 1:length(body)){
  #   message(paste0("Pack ", i, "/", length(body)))

  #   response <- httr::POST(
  #     base_url,
  #     body = body[[i]],
  #     httr::add_headers(.headers = headers),
  #     encode = "json")

  #   if(response$status_code %in% c(200, 201)) {
  #      response_content = utils::str(httr::content(response))
  #     message("HTTP ", response$status_code,":\n",
  #             "Request successfully received!\nProject ID: ",
  #             response_content$id)

  #     posted <- posted + 1
  #   }
  #   else if(response$status_code == 413){
  #     message("HTTP ", response$status_code,":\n",
  #             "Payload (file) is too large. Try sending a smaller list or send us an email.")
  #   }
  #   else {
  #     message("Something went wrong!\nStatus code:", response$status_code)
  #     message(utils::str(httr::content(response)))
  #   }
  #   message(paste0("[",paste0(rep("=", times = i), collapse = ""),
  #                  paste0(rep(" ", times = (length(body)-i)), collapse = ""),"]"))
  # }
  # if(posted == length(body)){
  #   message("\nResults will soon be available in your Projects module")
  # } else if(posted > 0){
  #   message("\nAt least one of your packs could not be sent, see previous messages for more details.
  #           \nResults for submitted packs will soon be available in your Projects module")
  # }

  response <- httr::POST(
    base_url,
    body = body,
    httr::add_headers(.headers = headers),
    httr::use_proxy(url = extra_arguments$proxy_url,
                    port = extra_arguments$proxy_port),
    encode = "json")

  res_content <- NULL
  try(res_content <- httr::content(response), silent = TRUE)

  if(! httr::status_code(response) %in% c(200,201,202)) {

    if(httr::status_code(response) %in% c(408,413,502,504,599)){
      message("Status code: ", httr::status_code(response),"\n",
              "Payload (file) is too large. Try sending a smaller pack_list.")
    } else if(httr::status_code(response) == 503){
      message("API Status code: ", httr::status_code(response),
              ".\nContent: Model Update - Service Unavailable.",
              ".\nPlease try again later.")
    } else if(httr::status_code(response) == 401){
      message("API Status code: ", httr::status_code(response),
              ".\nContent: Expired Authentication.",
              ".\nPlease run 'login()' again.")
    } else{
      message("API Status code: ", httr::status_code(response),
              ".\nContent: ", httr::content(response, "text"),
              ".\nSomething went wrong in the api, please check if you have the latest version of this package and/or try again later.")
    }

  } else{
    if( "created" %in% res_content[["status"]] ) {
      message("\nStatus code: 200 - Request successfully received for update!\n",
              "Results will soon be available in your Projects module.\n")
    } else {
      message("Something went wrong when sending to update!\nContent:")
      message(utils::str(res_content))
    }
  }
}


